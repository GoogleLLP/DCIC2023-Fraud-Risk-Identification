{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>定义部分：参考<a href=\"https://github.com/WangliLin/xunfei2021_car_loan_top1\">https://github.com/WangliLin/xunfei2021_car_loan_top1</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:41:23.801037Z",
     "start_time": "2023-02-16T02:41:23.793050Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import variation\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ks_2samp, kstatvar\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, KBinsDiscretizer, LabelEncoder, MinMaxScaler, PowerTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def train_lgb_kfold(X_train, y_train, X_test, n_fold=5, cate_feats=None):\n",
    "    '''train lightgbm with k-fold split'''\n",
    "    gbms = []\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    oof_preds = np.zeros((X_train.shape[0],))\n",
    "    test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        logging.info(f'############ fold {fold} ###########')\n",
    "        X_tr, X_val, y_tr, y_val = X_train.iloc[train_index], X_train.iloc[val_index], y_train[train_index], y_train[val_index]\n",
    "        dtrain = lgb.Dataset(X_tr, y_tr, categorical_feature=cate_feats)\n",
    "        dvalid = lgb.Dataset(X_val, y_val, categorical_feature=cate_feats, reference=dtrain)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 1024\n",
    "        }\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=300,\n",
    "                        valid_sets=[dtrain, dvalid],\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=20)\n",
    "\n",
    "        oof_preds[val_index] = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        test_preds += gbm.predict(X_test, num_iteration=gbm.best_iteration) / kfold.n_splits\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms, oof_preds, test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>读取数据部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:41:24.995044Z",
     "start_time": "2023-02-16T02:41:23.802046Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/账户交易信息.csv')\n",
    "data_static = pd.read_csv('../data/账户静态信息.csv')\n",
    "data_label = pd.read_csv('../data/训练集标签.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>特征工程部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:41:25.000041Z",
     "start_time": "2023-02-16T02:41:24.997042Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ks(_data: DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    检验每个月的入账出账是否同分布\n",
    "    \"\"\"\n",
    "    _df = pd.pivot_table(_data, values=\"jyje\", index=\"日期\", columns=\"年月\")\n",
    "    _df = _df.fillna(0)\n",
    "    if _df.shape[1] < 2:\n",
    "        return 1\n",
    "    result = 0\n",
    "    for j in range(_df.shape[1] - 1):\n",
    "        result = result + ks_2samp(_df.iloc[:, j], _df.iloc[:, j+1]).statistic\n",
    "    return result / (_df.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.473558Z",
     "start_time": "2023-02-16T02:41:25.001035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [04:24<00:00, 22.71it/s]\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "users = data.zhdh.unique().tolist()\n",
    "for user_id in tqdm(users):\n",
    "    data_sample = data[data.zhdh == user_id].reset_index(drop=True)\n",
    "    data_sample[\"转账日期\"] = data_sample[\"jyrq\"] + \" \" + data_sample[\"jysj\"]\n",
    "    data_sample[\"转账日期\"] = pd.to_datetime(data_sample[\"转账日期\"])\n",
    "    data_sample = data_sample.sort_values(\"转账日期\")\n",
    "    data_sample[\"年月\"] = data_sample[\"转账日期\"].apply(lambda x: x.year * 100 + x.month)\n",
    "    data_sample[\"日期\"] = data_sample[\"转账日期\"].apply(lambda x: x.day)\n",
    "    data_sample[\"对方账户\"] = data_sample[\"dfzh\"] + data_sample[\"dfhh\"]\n",
    "    \n",
    "    # 最大进账频次，最小进账频次，最大出账频次，最小出账频次\n",
    "    max_in_cnt = data_sample[data_sample[\"jdbj\"] == 1][\"jyrq\"].value_counts().max()\n",
    "    min_in_cnt = data_sample[data_sample[\"jdbj\"] == 1][\"jyrq\"].value_counts().min()\n",
    "    max_out_cnt = data_sample[data_sample[\"jdbj\"] == 0][\"jyrq\"].value_counts().max()\n",
    "    min_out_cnt = data_sample[data_sample[\"jdbj\"] == 0][\"jyrq\"].value_counts().min()\n",
    "    \n",
    "    # 对方账户的出现频次的最大值、最小值、中位数\n",
    "    max_df_cnt = data_sample[\"对方账户\"].value_counts().max()\n",
    "    min_df_cnt = data_sample[\"对方账户\"].value_counts().min()\n",
    "    median_df_cnt = data_sample[\"对方账户\"].value_counts().median()\n",
    "    \n",
    "    # 转入金额、转出金额的变异系数\n",
    "    in_amt_variation = variation(data_sample[data_sample.jdbj == 1].jyje.values) \n",
    "    out_amt_variation = variation(data_sample[data_sample.jdbj == 0].jyje)\n",
    "    \n",
    "    # 临近月的转账分布一致性\n",
    "    in_ks = get_ks(data_sample[data_sample[\"jdbj\"] == 1])\n",
    "    out_ks = get_ks(data_sample[data_sample[\"jdbj\"] == 0])\n",
    "    \n",
    "    all_cnt = data_sample.shape[0] # 操作次数\n",
    "    \n",
    "    # 转入次数、转出次数、转入次数占比\n",
    "    in_cnt = data_sample.jdbj.sum()\n",
    "    out_cnt = all_cnt - in_cnt\n",
    "    in_ratio = in_cnt / all_cnt\n",
    "    \n",
    "    # 转入金额、转出金额、转入金额占比\n",
    "    in_amt = data_sample[data_sample.jdbj == 1].jyje.sum()\n",
    "    out_amt = data_sample[data_sample.jdbj == 0].jyje.sum()\n",
    "    in_amt_ratio = in_amt / (in_amt + out_amt)\n",
    "    \n",
    "    # 转入人数、转出人数、转入人数占比\n",
    "    in_user_cnt = data_sample[data_sample.jdbj == 1].dfzh.nunique()\n",
    "    out_user_cnt = data_sample[data_sample.jdbj == 0].dfzh.nunique()\n",
    "    in_user_ratio = in_user_cnt / (in_user_cnt + out_user_cnt)\n",
    "    \n",
    "    date_cnt = data_sample.jyrq.nunique() # 转账日期数\n",
    "    \n",
    "    d[user_id] = [all_cnt, in_cnt, out_cnt, in_ratio, in_amt, out_amt, in_amt_ratio, in_amt_variation, out_amt_variation, in_user_cnt, out_user_cnt, in_user_ratio, date_cnt, max_in_cnt, min_in_cnt, max_out_cnt, min_out_cnt, max_df_cnt, min_df_cnt, median_df_cnt, in_ks, out_ks]\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(d).T.reset_index()\n",
    "data_df.columns = ['zhdh', 'all_cnt', 'in_cnt', 'out_cnt', 'in_ratio', 'in_amt', 'out_amt', 'in_amt_ratio', \"in_amt_variation\", \"out_amt_variation\", 'in_user_cnt', 'out_user_cnt', 'in_user_ratio', 'date_cnt', \"max_in_cnt\", \"min_in_cnt\", \"max_out_cnt\", \"min_out_cnt\", \"max_df_cnt\", \"min_df_cnt\", \"median_df_cnt\", \"in_ks\", \"out_ks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>合并标签部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.486560Z",
     "start_time": "2023-02-16T02:45:49.474559Z"
    }
   },
   "outputs": [],
   "source": [
    "data_static.columns = ['zhdh', 'khrq', 'khjgdh', 'xb', 'age']\n",
    "df_feats = pd.merge(left=data_df, right=data_static[['zhdh', 'xb', 'age']], on='zhdh', how='left')\n",
    "df_final = pd.merge(left=df_feats, right=data_label, on='zhdh', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>准备数据集</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.497559Z",
     "start_time": "2023-02-16T02:45:49.488560Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_final[df_final.black_flag.notnull()].reset_index(drop=True)\n",
    "df_test = df_final[df_final.black_flag.isnull()].reset_index(drop=True)\n",
    "\n",
    "feats = df_train.columns[1:-1].tolist()\n",
    "X_train = df_train[feats]\n",
    "y_train = df_train['black_flag']\n",
    "X_test = df_test[feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>使用SMOTE增强</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.501560Z",
     "start_time": "2023-02-16T02:45:49.498559Z"
    }
   },
   "outputs": [],
   "source": [
    "# smo = SMOTE(random_state=42)\n",
    "# X_train, y_train = smo.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>开始训练</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.865558Z",
     "start_time": "2023-02-16T02:45:49.503563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 10:45:49,509 : INFO : ############ fold 0 ###########\n",
      "2023-02-16 10:45:49,609 : INFO : ############ fold 1 ###########\n",
      "2023-02-16 10:45:49,684 : INFO : ############ fold 2 ###########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.987326\tvalid_1's auc: 0.967685\n",
      "[100]\ttraining's auc: 0.998559\tvalid_1's auc: 0.972315\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's auc: 0.998507\tvalid_1's auc: 0.973056\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.988536\tvalid_1's auc: 0.951389\n",
      "[100]\ttraining's auc: 0.998247\tvalid_1's auc: 0.954074\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's auc: 0.997355\tvalid_1's auc: 0.955463\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.976059\tvalid_1's auc: 0.924259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 10:45:49,728 : INFO : ############ fold 3 ###########\n",
      "2023-02-16 10:45:49,795 : INFO : ############ fold 4 ###########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.989144\tvalid_1's auc: 0.933241\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.993003\tvalid_1's auc: 0.9375\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.985972\tvalid_1's auc: 0.943981\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's auc: 0.987847\tvalid_1's auc: 0.945185\n"
     ]
    }
   ],
   "source": [
    "gbms, oof_preds, test_preds = train_lgb_kfold(X_train, y_train, X_test, n_fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>搜索最优阈值</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.913558Z",
     "start_time": "2023-02-16T02:45:49.867560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阈值: 0.3659654417630336\n",
      "训练集的f1: 0.8926326199053471\n"
     ]
    }
   ],
   "source": [
    "def gen_thres_new(df_train, oof_preds):\n",
    "    df_train['oof_preds'] = oof_preds\n",
    "    quantile_point = df_train['black_flag'].mean()\n",
    "    thres = df_train['oof_preds'].quantile(1 - quantile_point)\n",
    "\n",
    "    _thresh = []\n",
    "    for thres_item in np.arange(thres - 0.2, thres + 0.2, 0.01):\n",
    "        _thresh.append(\n",
    "            [thres_item, f1_score(df_train['black_flag'], np.where(oof_preds > thres_item, 1, 0), average='macro')])\n",
    "\n",
    "    _thresh = np.array(_thresh)\n",
    "    best_id = _thresh[:, 1].argmax()\n",
    "    best_thresh = _thresh[best_id][0]\n",
    "\n",
    "    print(\"阈值: {}\\n训练集的f1: {}\".format(best_thresh, _thresh[best_id][1]))\n",
    "    return best_thresh\n",
    "\n",
    "best_thresh = gen_thres_new(df_train, oof_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>生成提交结果</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T02:45:49.930559Z",
     "start_time": "2023-02-16T02:45:49.914558Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['black_flag'] = np.where(test_preds > best_thresh, 1, 0)\n",
    "df_test[['zhdh', 'black_flag']].to_csv(\"../data/submit_%s.csv\" % datetime.now().strftime(\"%Y-%m-%dT%H-%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
