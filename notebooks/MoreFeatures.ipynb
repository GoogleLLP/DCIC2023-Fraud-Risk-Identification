{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>定义部分：参考<a href=\"https://github.com/WangliLin/xunfei2021_car_loan_top1\">https://github.com/WangliLin/xunfei2021_car_loan_top1</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T11:58:28.389838Z",
     "start_time": "2023-02-13T11:58:28.380838Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import variation\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, KBinsDiscretizer, LabelEncoder, MinMaxScaler, PowerTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def train_lgb_kfold(X_train, y_train, X_test, n_fold=5, cate_feats=None):\n",
    "    '''train lightgbm with k-fold split'''\n",
    "    gbms = []\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    oof_preds = np.zeros((X_train.shape[0],))\n",
    "    test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        logging.info(f'############ fold {fold} ###########')\n",
    "        X_tr, X_val, y_tr, y_val = X_train.iloc[train_index], X_train.iloc[val_index], y_train[train_index], y_train[val_index]\n",
    "        dtrain = lgb.Dataset(X_tr, y_tr, categorical_feature=cate_feats)\n",
    "        dvalid = lgb.Dataset(X_val, y_val, categorical_feature=cate_feats, reference=dtrain)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 1024\n",
    "        }\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=300,\n",
    "                        valid_sets=[dtrain, dvalid],\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=20)\n",
    "\n",
    "        oof_preds[val_index] = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        test_preds += gbm.predict(X_test, num_iteration=gbm.best_iteration) / kfold.n_splits\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms, oof_preds, test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>读取数据部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T11:58:29.475837Z",
     "start_time": "2023-02-13T11:58:28.390826Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/账户交易信息.csv')\n",
    "data_static = pd.read_csv('../data/账户静态信息.csv')\n",
    "data_label = pd.read_csv('../data/训练集标签.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>特征工程部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:39.651952Z",
     "start_time": "2023-02-13T11:58:29.477838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [03:09<00:00, 31.59it/s]\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "users = data.zhdh.unique().tolist()\n",
    "for user_id in tqdm(users):\n",
    "    data_sample = data[data.zhdh == user_id].reset_index(drop=True)\n",
    "    data_sample[\"转账日期\"] = data_sample[\"jyrq\"] + \" \" + data_sample[\"jysj\"]\n",
    "    data_sample[\"转账日期\"] = pd.to_datetime(data_sample[\"转账日期\"])\n",
    "    # 最大进账频次，最小进账频次，最大出账频次，最小出账频次\n",
    "    max_in_cnt = data_sample[data_sample[\"jdbj\"] == 1][\"jyrq\"].value_counts().max()\n",
    "    min_in_cnt = data_sample[data_sample[\"jdbj\"] == 1][\"jyrq\"].value_counts().min()\n",
    "    max_out_cnt = data_sample[data_sample[\"jdbj\"] == 0][\"jyrq\"].value_counts().max()\n",
    "    min_out_cnt = data_sample[data_sample[\"jdbj\"] == 0][\"jyrq\"].value_counts().min()\n",
    "    \n",
    "    all_cnt = data_sample.shape[0] # 操作次数\n",
    "    in_cnt = data_sample.jdbj.sum() # 转入次数、转出次数、转入次数占比\n",
    "    out_cnt = all_cnt - in_cnt\n",
    "    in_ratio = in_cnt / all_cnt\n",
    "    in_amt = data_sample[data_sample.jdbj == 1].jyje.sum() # 转入金额、转出金额、转入金额占比\n",
    "    out_amt = data_sample[data_sample.jdbj == 0].jyje.sum()\n",
    "    in_amt_variation = variation(data_sample[data_sample.jdbj == 1].jyje.values) # 转入金额、转出金额的变异系数\n",
    "    out_amt_variation = variation(data_sample[data_sample.jdbj == 0].jyje)\n",
    "    in_amt_ratio = in_amt / (in_amt + out_amt)\n",
    "    in_user_cnt = data_sample[data_sample.jdbj == 1].dfzh.nunique() # 转入人数、转出人数、转入人数占比\n",
    "    out_user_cnt = data_sample[data_sample.jdbj == 0].dfzh.nunique()\n",
    "    in_user_ratio = in_user_cnt / (in_user_cnt + out_user_cnt)\n",
    "    date_cnt = data_sample.jyrq.nunique() # 转账日期数\n",
    "    \n",
    "    d[user_id] = [all_cnt, in_cnt, out_cnt, in_ratio, in_amt, out_amt, in_amt_ratio, in_amt_variation, out_amt_variation, in_user_cnt, out_user_cnt, in_user_ratio, date_cnt, max_in_cnt, min_in_cnt, max_out_cnt, min_out_cnt]\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(d).T.reset_index()\n",
    "data_df.columns = ['zhdh', 'all_cnt', 'in_cnt', 'out_cnt', 'in_ratio', 'in_amt', 'out_amt', 'in_amt_ratio', \"in_amt_variation\", \"out_amt_variation\", 'in_user_cnt', 'out_user_cnt', 'in_user_ratio', 'date_cnt', \"max_in_cnt\", \"min_in_cnt\", \"max_out_cnt\", \"min_out_cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>合并标签部分</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:39.670946Z",
     "start_time": "2023-02-13T12:01:39.652943Z"
    }
   },
   "outputs": [],
   "source": [
    "data_static.columns = ['zhdh', 'khrq', 'khjgdh', 'xb', 'age']\n",
    "df_feats = pd.merge(left=data_df, right=data_static[['zhdh', 'xb', 'age']], on='zhdh', how='left')\n",
    "df_final = pd.merge(left=df_feats, right=data_label, on='zhdh', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>准备数据集</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:39.677956Z",
     "start_time": "2023-02-13T12:01:39.671953Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_final[df_final.black_flag.notnull()].reset_index(drop=True)\n",
    "df_test = df_final[df_final.black_flag.isnull()].reset_index(drop=True)\n",
    "\n",
    "feats = df_train.columns[1:-1].tolist()\n",
    "X_train = df_train[feats]\n",
    "y_train = df_train['black_flag']\n",
    "X_test = df_test[feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>使用SMOTE增强</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:39.684954Z",
     "start_time": "2023-02-13T12:01:39.678944Z"
    }
   },
   "outputs": [],
   "source": [
    "# smo = SMOTE(random_state=42)\n",
    "# X_train, y_train = smo.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>开始训练</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:40.058944Z",
     "start_time": "2023-02-13T12:01:39.685945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 20:01:39,702 : INFO : ############ fold 0 ###########\n",
      "2023-02-13 20:01:39,771 : INFO : ############ fold 1 ###########\n",
      "2023-02-13 20:01:39,829 : INFO : ############ fold 2 ###########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.986534\tvalid_1's auc: 0.965833\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.989126\tvalid_1's auc: 0.967685\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.986406\tvalid_1's auc: 0.949352\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's auc: 0.989774\tvalid_1's auc: 0.951019\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.987454\tvalid_1's auc: 0.919259\n",
      "[100]\ttraining's auc: 0.997789\tvalid_1's auc: 0.928519\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's auc: 0.998356\tvalid_1's auc: 0.929167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 20:01:39,920 : INFO : ############ fold 3 ###########\n",
      "2023-02-13 20:01:39,980 : INFO : ############ fold 4 ###########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.988501\tvalid_1's auc: 0.935556\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.991701\tvalid_1's auc: 0.940278\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's auc: 0.985747\tvalid_1's auc: 0.941759\n",
      "[100]\ttraining's auc: 0.996817\tvalid_1's auc: 0.953796\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's auc: 0.996279\tvalid_1's auc: 0.954444\n"
     ]
    }
   ],
   "source": [
    "gbms, oof_preds, test_preds = train_lgb_kfold(X_train, y_train, X_test, n_fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>搜索最优阈值</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:40.110943Z",
     "start_time": "2023-02-13T12:01:40.061945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阈值: 0.39557224470836455\n",
      "训练集的f1: 0.8847767454374158\n"
     ]
    }
   ],
   "source": [
    "def gen_thres_new(df_train, oof_preds):\n",
    "    df_train['oof_preds'] = oof_preds\n",
    "    quantile_point = df_train['black_flag'].mean()\n",
    "    thres = df_train['oof_preds'].quantile(1 - quantile_point)\n",
    "\n",
    "    _thresh = []\n",
    "    for thres_item in np.arange(thres - 0.2, thres + 0.2, 0.01):\n",
    "        _thresh.append(\n",
    "            [thres_item, f1_score(df_train['black_flag'], np.where(oof_preds > thres_item, 1, 0), average='macro')])\n",
    "\n",
    "    _thresh = np.array(_thresh)\n",
    "    best_id = _thresh[:, 1].argmax()\n",
    "    best_thresh = _thresh[best_id][0]\n",
    "\n",
    "    print(\"阈值: {}\\n训练集的f1: {}\".format(best_thresh, _thresh[best_id][1]))\n",
    "    return best_thresh\n",
    "\n",
    "best_thresh = gen_thres_new(df_train, oof_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>生成提交结果</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T12:01:40.131943Z",
     "start_time": "2023-02-13T12:01:40.112944Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['black_flag'] = np.where(test_preds > best_thresh, 1, 0)\n",
    "df_test[['zhdh', 'black_flag']].to_csv(\"../data/submit_%s.csv\" % datetime.now().strftime(\"%Y-%m-%dT%H-%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
